# ðŸ› ï¸ Task 1 â€“ Data Cleaning & Preprocessing (Titanic Dataset)

Welcome to my submission for **Task 1 of the AI & ML Internship**, where I worked on the Titanic dataset to explore and practice **real-world data preprocessing techniques**. This task was not just about fulfilling the minimum requirements â€” I took this as a learning opportunity to go deeper, explore beyond the checklist, and truly understand each step.

---

## ðŸ§  What I Learned

Throughout this task, I focused on *learning by doing*. I researched, experimented, and debugged everything myself instead of just following tutorials blindly. Hereâ€™s what I learned in detail:

### ðŸ”¹ Understanding the Data
- Explored data types (`int`, `float`, `object`)
- Used `.info()`, `.describe()`, `.isnull()` to understand structure and missing values
- Identified columns that needed special handling (like `'Cabin'`, `'Embarked'`, `'Age'`)

### ðŸ”¹ Handling Missing Values
- Replaced missing `Age` values with the **median** (better for skewed distributions)
- Filled missing `Embarked` entries using the **mode**
- Dropped the `Cabin` column as it had over 77% missing values

### ðŸ”¹ Categorical Variable Encoding
- Converted `Sex` to numeric (male â†’ 0, female â†’ 1)
- One-hot encoded `Embarked` to avoid dummy variable trap
- Extracted **Title** from `Name` (Mr, Miss, Mrs, etc.) and encoded it after grouping rare titles

### ðŸ”¹ Feature Engineering (Extra Step)
I went beyond the basic task by:
- Extracting `Title` from the `Name` column to uncover social insights
- Creating a new feature called `FamilySize` (SibSp + Parch + 1)

### ðŸ”¹ Feature Scaling
- Standardized `Age` and `Fare` using **StandardScaler** from `sklearn`
- Ensured data was normally distributed with mean â‰ˆ 0 and std â‰ˆ 1

### ðŸ”¹ Outlier Detection and Removal
- Used **boxplots** and the **IQR (Interquartile Range)** method to identify and remove extreme values from `Age` and `Fare`

---

## ðŸ’¾ Files in This Repository

| File Name | Description |
|-----------|-------------|
| `task1.ipynb` | Jupyter notebook containing all code, logic, and plots |
| `titanic_final_cleaned.csv` | Final cleaned and preprocessed dataset |
| `README.md` | You're reading it :) |
| (Optional) screenshots/plots | For visual proof if needed |

---

## ðŸ“ˆ Technologies Used

- **Python** (Pandas, NumPy, Matplotlib, Seaborn)
- **Jupyter Notebook**
- **scikit-learn (StandardScaler)**
- GitHub (for version control and submission)

---

## ðŸ‘©â€ðŸ’» Done By Me â€” With Full Understanding

I want to clearly state that:
> This task was **entirely completed by me â€” Leesha Gulati** â€” without copying from others. I took my time to understand each line of code, explored errors, looked up documentation, and learned **how data preprocessing works in real ML pipelines.**

This is more than just a submission; itâ€™s a reflection of my learning journey. ðŸ™Œ

---

## ðŸ“Œ Summary of Key Concepts I Now Understand

- Types of missing data (MCAR, MAR, MNAR)
- Encoding methods (Label, One-Hot, Ordinal)
- Standardization vs. Normalization
- Outlier detection using IQR & boxplots
- Why data cleaning directly affects model performance

---

## âœ… Status: Completed

This repository is complete and ready for review.  
Iâ€™m excited to continue learning in this internship and improve with every task!



Thank you for reviewing my work!  
â€” *Leesha Gulati*
